import API_BASE_URL from '../config/api.js';

class AIService {
  constructor() {
    this.apiKey = import.meta.env.VITE_OPENAI_API_KEY || import.meta.env.VITE_AI_API_KEY;
    this.baseURL = API_BASE_URL;
    this.provider = import.meta.env.VITE_AI_PROVIDER || 'openai'; // openai, gemini, claude, local
    this.lastResponses = new Set(); // Track recent responses to avoid repetition
    this.conversationContext = new Map(); // Store conversation contexts
  }

  /**
   * Get AI response from OpenAI
   * @param {string} message - User message
   * @param {Array} conversationHistory - Previous conversation context
   * @returns {Promise<string>} AI response
   */
  async getOpenAIResponse(message, conversationHistory = []) {
    const messages = [
      {
        role: "system",
        content: `B·∫°n l√† StudySync AI, m·ªôt tr·ª£ l√Ω h·ªçc t·∫≠p th√¥ng minh v√† th√¢n thi·ªán cho h·ªçc sinh Vi·ªát Nam. 

NHI·ªÜM V·ª§:
- H·ªó tr·ª£ h·ªçc t·∫≠p c√°c m√¥n: To√°n, L√Ω, H√≥a, Sinh, VƒÉn, Anh, L·ªãch s·ª≠, ƒê·ªãa l√Ω
- Gi·∫£i th√≠ch kh√°i ni·ªám m·ªôt c√°ch d·ªÖ hi·ªÉu
- ƒê∆∞a ra g·ª£i √Ω h·ªçc t·∫≠p hi·ªáu qu·∫£
- T·∫°o k·∫ø ho·∫°ch h·ªçc t·∫≠p c√° nh√¢n
- H·ªó tr·ª£ gi·∫£i b√†i t·∫≠p t·ª´ng b∆∞·ªõc

PHONG C√ÅCH:
- S·ª≠ d·ª•ng ti·∫øng Vi·ªát t·ª± nhi√™n, th√¢n thi·ªán
- Emoji ph√π h·ª£p ƒë·ªÉ t·∫°o c·∫£m gi√°c g·∫ßn g≈©i
- Tr·∫£ l·ªùi chi ti·∫øt nh∆∞ng d·ªÖ hi·ªÉu
- Khuy·∫øn kh√≠ch v√† ƒë·ªông vi√™n h·ªçc sinh
- ƒê∆∞a ra v√≠ d·ª• c·ª• th·ªÉ khi c·∫ßn thi·∫øt

ƒê·ªäNH D·∫†NG TR·∫§U L·ªúI:
- S·ª≠ d·ª•ng **in ƒë·∫≠m** cho t·ª´ kh√≥a quan tr·ªçng
- S·ª≠ d·ª•ng bullet points (‚Ä¢) cho danh s√°ch
- Chia nh·ªè th√¥ng tin th√†nh c√°c ph·∫ßn r√µ r√†ng
- Lu√¥n k·∫øt th√∫c b·∫±ng c√¢u h·ªèi ƒë·ªÉ t∆∞∆°ng t√°c ti·∫øp`
      },
      ...conversationHistory.slice(-10), // Keep last 10 messages for context
      {
        role: "user",
        content: message
      }
    ];

    try {
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: 'gpt-3.5-turbo',
          messages: messages,
          max_tokens: 1000,
          temperature: 0.7,
          presence_penalty: 0.6,
          frequency_penalty: 0.3
        })
      });

      if (!response.ok) {
        throw new Error(`OpenAI API error: ${response.status}`);
      }

      const data = await response.json();
      return data.choices[0].message.content;
    } catch (error) {
      console.error('OpenAI API Error:', error);
      throw error;
    }
  }

  /**
   * Get AI response from Google Gemini
   * @param {string} message - User message
   * @param {Array} conversationHistory - Previous conversation context
   * @returns {Promise<string>} AI response
   */
  async getGeminiResponse(message, conversationHistory = []) {
    const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
    
    console.log('üîç Gemini API Key check:', {
      hasKey: !!apiKey,
      keyPreview: apiKey ? apiKey.substring(0, 10) + '...' : 'None',
      keyLength: apiKey ? apiKey.length : 0
    });
    
    if (!apiKey || apiKey === 'your_gemini_api_key_here') {
      throw new Error('Gemini API key not properly configured');
    }

    // Test if the API key is valid by checking available models first
    try {
      console.log('üîç Testing Gemini API key validity...');
      const modelsResponse = await fetch(`https://generativelanguage.googleapis.com/v1/models?key=${apiKey}`);
      
      if (!modelsResponse.ok) {
        const errorText = await modelsResponse.text();
        console.error('‚ùå Gemini API key test failed:', errorText);
        throw new Error(`Invalid API key or no access: ${modelsResponse.status}`);
      }
      
      const modelsData = await modelsResponse.json();
      console.log('‚úÖ Available Gemini models:', modelsData.models?.map(m => m.name) || 'None');
    } catch (keyTestError) {
      console.error('‚ùå Gemini API key validation failed:', keyTestError.message);
      throw new Error(`Gemini API access issue: ${keyTestError.message}`);
    }

    const prompt = `B·∫°n l√† StudySync AI, tr·ª£ l√Ω h·ªçc t·∫≠p th√¥ng minh v√† th√¢n thi·ªán cho h·ªçc sinh Vi·ªát Nam.

NHI·ªÜM V·ª§: H·ªó tr·ª£ h·ªçc t·∫≠p c√°c m√¥n h·ªçc, gi·∫£i th√≠ch kh√°i ni·ªám, ƒë∆∞a ra l·ªùi khuy√™n h·ªçc t·∫≠p hi·ªáu qu·∫£.

PHONG C√ÅCH: Th√¢n thi·ªán, chi ti·∫øt, d·ªÖ hi·ªÉu, s·ª≠ d·ª•ng emoji ph√π h·ª£p.

${conversationHistory.length > 0 ? `L·ªäCH S·ª¨ TR∆Ø·ªöC ƒê√ì:\n${conversationHistory.slice(-3).map(msg => `${msg.role === 'user' ? 'üë§ H·ªçc sinh' : 'ü§ñ AI'}: ${msg.content}`).join('\n')}\n\n` : ''}üë§ C√ÇUH·ªéI M·ªöI: ${message}

ü§ñ TR·∫¢ L·ªúI:`;

    try {
      console.log('üì§ Sending request to Gemini API...');
      
      // Try different Gemini models in order of preference
      const models = [
        'gemini-1.5-flash',
        'gemini-1.5-pro', 
        'gemini-pro'
      ];
      
      let response;
      let lastError;
      
      for (const model of models) {
        try {
          console.log(`üîÑ Trying model: ${model}`);
          response = await fetch(`https://generativelanguage.googleapis.com/v1/models/${model}:generateContent?key=${apiKey}`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              contents: [{
                parts: [{
                  text: prompt
                }]
              }],
              generationConfig: {
                temperature: 0.7,
                topK: 40,
                topP: 0.95,
                maxOutputTokens: 1000,
              },
              safetySettings: [
                {
                  category: "HARM_CATEGORY_HARASSMENT",
                  threshold: "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                  category: "HARM_CATEGORY_HATE_SPEECH", 
                  threshold: "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                  category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                  threshold: "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                  category: "HARM_CATEGORY_DANGEROUS_CONTENT",
                  threshold: "BLOCK_MEDIUM_AND_ABOVE"
                }
              ]
            })
          });

          console.log(`üì• Gemini API response status for ${model}:`, response.status);

          if (response.ok) {
            const data = await response.json();
            console.log('üì¶ Gemini API response data:', data);
            
            if (data.candidates && data.candidates[0] && data.candidates[0].content) {
              const responseText = data.candidates[0].content.parts[0].text;
              console.log(`‚úÖ Gemini response received from ${model}:`, responseText.substring(0, 100) + '...');
              return responseText;
            }
          } else {
            const errorText = await response.text();
            console.warn(`‚ö†Ô∏è Model ${model} failed:`, errorText);
            lastError = new Error(`${model}: ${response.status} - ${errorText}`);
          }
        } catch (modelError) {
          console.warn(`‚ö†Ô∏è Model ${model} error:`, modelError.message);
          lastError = modelError;
          continue;
        }
      }

      // If we get here, all models failed
      throw new Error(`All Gemini models failed. Last error: ${lastError?.message}`);
    } catch (error) {
      console.error('‚ùå Gemini API Error:', {
        message: error.message,
        stack: error.stack
      });
      throw error;
    }
  }

  /**
   * Get AI response from local/backend API
   * @param {string} message - User message
   * @param {Array} conversationHistory - Previous conversation context
   * @returns {Promise<string>} AI response
   */
  async getLocalAIResponse(message, conversationHistory = []) {
    try {
      const response = await fetch(`${this.baseURL}/ai/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${localStorage.getItem('accessToken')}`
        },
        body: JSON.stringify({
          message,
          conversationHistory: conversationHistory.slice(-10)
        })
      });

      if (!response.ok) {
        throw new Error(`Local AI API error: ${response.status}`);
      }

      const data = await response.json();
      return data.response;
    } catch (error) {
      console.error('Local AI API Error:', error);
      throw error;
    }
  }

  /**
   * Get fallback responses when AI services are unavailable
   * @param {string} message - User message
   * @returns {string} Fallback response
   */
  getFallbackResponse(message) {
    const responses = {
      // Greeting responses
      greetings: [
        "üëã Xin ch√†o! T√¥i l√† StudySync AI. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n v·ªõi c√°c c√¢u h·ªèi v·ªÅ h·ªçc t·∫≠p. B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ h√¥m nay?",
        "üåü Ch√†o b·∫°n! T√¥i s·∫µn s√†ng h·ªó tr·ª£ b·∫°n h·ªçc t·∫≠p. H√£y cho t√¥i bi·∫øt b·∫°n mu·ªën t√¨m hi·ªÉu v·ªÅ ch·ªß ƒë·ªÅ n√†o nh√©!",
        "üéì Hello! T√¥i l√† tr·ª£ l√Ω AI c·ªßa StudySync. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n gi·∫£i ƒë√°p th·∫Øc m·∫Øc v·ªÅ h·ªçc t·∫≠p."
      ],

      // Study help responses
      study: [
        "üìö **G·ª£i √Ω h·ªçc t·∫≠p hi·ªáu qu·∫£:**\n\n‚Ä¢ **Pomodoro Technique:** H·ªçc 25 ph√∫t, ngh·ªâ 5 ph√∫t\n‚Ä¢ **Active Recall:** T·ª± ki·ªÉm tra ki·∫øn th·ª©c thay v√¨ ch·ªâ ƒë·ªçc l·∫°i\n‚Ä¢ **Spaced Repetition:** √în t·∫≠p theo kho·∫£ng th·ªùi gian tƒÉng d·∫ßn\n‚Ä¢ **Teach Others:** Gi·∫£i th√≠ch cho ng∆∞·ªùi kh√°c ƒë·ªÉ hi·ªÉu s√¢u h∆°n\n\nB·∫°n mu·ªën t√¨m hi·ªÉu chi ti·∫øt v·ªÅ ph∆∞∆°ng ph√°p n√†o kh√¥ng? ü§î",
        
        "üéØ **K·∫ø ho·∫°ch h·ªçc t·∫≠p th√¥ng minh:**\n\n**B∆∞·ªõc 1:** X√°c ƒë·ªãnh m·ª•c ti√™u c·ª• th·ªÉ\n**B∆∞·ªõc 2:** Chia nh·ªè ki·∫øn th·ª©c th√†nh t·ª´ng ph·∫ßn\n**B∆∞·ªõc 3:** L·∫≠p l·ªãch h·ªçc t·∫≠p h√†ng ng√†y\n**B∆∞·ªõc 4:** Th∆∞·ªùng xuy√™n ƒë√°nh gi√° v√† ƒëi·ªÅu ch·ªânh\n\nB·∫°n ƒëang h·ªçc m√¥n g√¨ v√† c·∫ßn l·∫≠p k·∫ø ho·∫°ch nh∆∞ th·∫ø n√†o? üìù",
        
        "üß† **Chi·∫øn l∆∞·ª£c ghi nh·ªõ hi·ªáu qu·∫£:**\n\n‚Ä¢ **Mind Map:** S∆° ƒë·ªì t∆∞ duy k·∫øt n·ªëi ki·∫øn th·ª©c\n‚Ä¢ **Flashcards:** Th·∫ª ghi nh·ªõ cho t·ª´ v·ª±ng, c√¥ng th·ª©c\n‚Ä¢ **Storytelling:** T·∫°o c√¢u chuy·ªán ƒë·ªÉ nh·ªõ th√¥ng tin\n‚Ä¢ **Visual Learning:** S·ª≠ d·ª•ng h√¨nh ·∫£nh, bi·ªÉu ƒë·ªì\n\nM√¥n h·ªçc n√†o b·∫°n ƒëang g·∫∑p kh√≥ khƒÉn trong vi·ªác ghi nh·ªõ? üé®"
      ],

      // Subject-specific responses
      math: [
        "üî¢ **To√°n h·ªçc - Ph∆∞∆°ng ph√°p h·ªçc hi·ªáu qu·∫£:**\n\n‚Ä¢ **Hi·ªÉu kh√°i ni·ªám:** Kh√¥ng h·ªçc thu·ªôc l√≤ng c√¥ng th·ª©c\n‚Ä¢ **Luy·ªán t·∫≠p ƒë·ªÅu ƒë·∫∑n:** Gi·∫£i b√†i t·∫≠p m·ªói ng√†y\n‚Ä¢ **T·ª´ d·ªÖ ƒë·∫øn kh√≥:** B·∫Øt ƒë·∫ßu v·ªõi b√†i c∆° b·∫£n\n‚Ä¢ **Ki·ªÉm tra l·∫°i:** Xem l·∫°i c√°ch gi·∫£i ƒë·ªÉ tr√°nh sai l·∫ßm\n\nB·∫°n ƒëang h·ªçc ch∆∞∆°ng n√†o v√† g·∫∑p kh√≥ khƒÉn g√¨? ü§ì"
      ],

      // Group study responses
      group: [
        "üë• **H·ªçc nh√≥m hi·ªáu qu·∫£ v·ªõi StudySync:**\n\n‚Ä¢ **T·∫°o nh√≥m:** T√¨m b·∫°n c√πng m·ª•c ti√™u h·ªçc t·∫≠p\n‚Ä¢ **Ph√¢n c√¥ng nhi·ªám v·ª•:** M·ªói ng∆∞·ªùi ch·ªãu tr√°ch nhi·ªám m·ªôt ph·∫ßn\n‚Ä¢ **Th·∫£o lu·∫≠n t√≠ch c·ª±c:** Chia s·∫ª ki·∫øn th·ª©c v√† gi·∫£i ƒë√°p th·∫Øc m·∫Øc\n‚Ä¢ **ƒê√°nh gi√° ti·∫øn ƒë·ªô:** Theo d√µi k·∫øt qu·∫£ h·ªçc t·∫≠p c·ªßa nh√≥m\n\nB·∫°n mu·ªën t·∫°o nh√≥m h·ªçc m√¥n g√¨? T√¥i c√≥ th·ªÉ g·ª£i √Ω c√°ch t·ªï ch·ª©c! üåü"
      ],

      // Default responses
      default: [
        "ü§î ƒê√¢y l√† m·ªôt c√¢u h·ªèi th√∫ v·ªã! M√¨nh c·∫ßn th√™m th√¥ng tin ƒë·ªÉ c√≥ th·ªÉ h·ªó tr·ª£ b·∫°n t·ªët h∆°n.\n\n**T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:**\n‚Ä¢ Gi·∫£i th√≠ch kh√°i ni·ªám h·ªçc t·∫≠p\n‚Ä¢ ƒê∆∞a ra ph∆∞∆°ng ph√°p h·ªçc hi·ªáu qu·∫£\n‚Ä¢ T·∫°o k·∫ø ho·∫°ch h·ªçc t·∫≠p\n‚Ä¢ G·ª£i √Ω t√†i li·ªáu h·ªçc t·∫≠p\n\nB·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n v·ªÅ v·∫•n ƒë·ªÅ b·∫°n ƒëang g·∫∑p ph·∫£i kh√¥ng? üòä",
        
        "üí° T√¥i hi·ªÉu b·∫°n ƒëang c·∫ßn h·ªó tr·ª£! ƒê·ªÉ ƒë∆∞a ra l·ªùi khuy√™n ph√π h·ª£p nh·∫•t, b·∫°n c√≥ th·ªÉ cho t√¥i bi·∫øt:\n\n‚Ä¢ B·∫°n ƒëang h·ªçc l·ªõp m·∫•y?\n‚Ä¢ M√¥n h·ªçc n√†o b·∫°n quan t√¢m?\n‚Ä¢ V·∫•n ƒë·ªÅ c·ª• th·ªÉ b·∫°n g·∫∑p ph·∫£i?\n\nV√≠ d·ª•: *\"T√¥i h·ªçc l·ªõp 10, ƒëang g·∫∑p kh√≥ khƒÉn v·ªõi m√¥n H√≥a h·ªçc, kh√¥ng hi·ªÉu v·ªÅ li√™n k·∫øt h√≥a h·ªçc\"*\n\nT√¥i s·∫Ω h·ªó tr·ª£ b·∫°n m·ªôt c√°ch chi ti·∫øt nh·∫•t! üéì"
      ]
    };

    const lowerMessage = message.toLowerCase();
    console.log(`üéØ Analyzing message for fallback response: "${lowerMessage}"`);
    
    // Add more sophisticated response selection
    let selectedResponse;
    
    // Greeting detection
    if (lowerMessage.includes('xin ch√†o') || lowerMessage.includes('hello') || lowerMessage.includes('hi') || lowerMessage.includes('ch√†o')) {
      selectedResponse = responses.greetings[Math.floor(Math.random() * responses.greetings.length)];
      console.log('üìã Selected greeting response');
    }
    // Math-related questions
    else if (lowerMessage.includes('to√°n') || lowerMessage.includes('math') || lowerMessage.includes('ph∆∞∆°ng tr√¨nh') || lowerMessage.includes('t√≠nh')) {
      selectedResponse = responses.math[0];
      console.log('üìã Selected math response');
    }
    // Group study questions
    else if (lowerMessage.includes('nh√≥m') || lowerMessage.includes('group') || lowerMessage.includes('team')) {
      selectedResponse = responses.group[0];
      console.log('üìã Selected group study response');
    }
    // General study questions
    else if (lowerMessage.includes('h·ªçc') || lowerMessage.includes('study') || lowerMessage.includes('√¥n') || lowerMessage.includes('b√†i t·∫≠p')) {
      selectedResponse = responses.study[Math.floor(Math.random() * responses.study.length)];
      console.log('üìã Selected study response');
    }
    // Subject-specific detection
    else if (lowerMessage.includes('l√Ω') || lowerMessage.includes('physics')) {
      selectedResponse = "‚öóÔ∏è **V·∫≠t l√Ω - H·ªçc hi·ªáu qu·∫£:**\n\n‚Ä¢ **Hi·ªÉu hi·ªán t∆∞·ª£ng:** Quan s√°t v√† ph√¢n t√≠ch hi·ªán t∆∞·ª£ng th·ª±c t·∫ø\n‚Ä¢ **C√¥ng th·ª©c:** N·∫Øm v·ªØng v√† √°p d·ª•ng ƒë√∫ng c√¥ng th·ª©c\n‚Ä¢ **Th√≠ nghi·ªám:** Th·ª±c h√†nh ƒë·ªÉ hi·ªÉu b·∫£n ch·∫•t\n‚Ä¢ **B√†i t·∫≠p:** Gi·∫£i t·ª´ d·ªÖ ƒë·∫øn kh√≥\n\nB·∫°n ƒëang h·ªçc ch∆∞∆°ng n√†o c·ªßa V·∫≠t l√Ω? üî¨";
      console.log('üìã Selected physics response');
    }
    else if (lowerMessage.includes('h√≥a') || lowerMessage.includes('chemistry')) {
      selectedResponse = "üß™ **H√≥a h·ªçc - Ph∆∞∆°ng ph√°p h·ªçc:**\n\n‚Ä¢ **B·∫£ng tu·∫ßn ho√†n:** H·ªçc thu·ªôc v√† hi·ªÉu c·∫•u tr√∫c\n‚Ä¢ **Ph∆∞∆°ng tr√¨nh:** C√¢n b·∫±ng v√† hi·ªÉu c∆° ch·∫ø\n‚Ä¢ **Th√≠ nghi·ªám:** Quan s√°t v√† ghi ch√©p k·ªπ\n‚Ä¢ **T√≠nh ch·∫•t:** Li√™n k·∫øt l√Ω thuy·∫øt v·ªõi th·ª±c t·∫ø\n\nB·∫°n c·∫ßn h·ªó tr·ª£ v·ªÅ ph·∫ßn n√†o c·ªßa H√≥a h·ªçc? üî¨";
      console.log('üìã Selected chemistry response');
    }
    // Default responses with more variety
    else {
      // Create more personalized default responses
      const personalizedDefaults = [
        ...responses.default,
        `ü§ñ T√¥i nh·∫≠n ƒë∆∞·ª£c c√¢u h·ªèi: "${message}"\n\nüí≠ **ƒê·ªÉ h·ªó tr·ª£ b·∫°n t·ªët h∆°n, t√¥i c·∫ßn:**\n‚Ä¢ Bi·∫øt m√¥n h·ªçc b·∫°n quan t√¢m\n‚Ä¢ C·∫•p ƒë·ªô h·ªçc t·∫≠p (l·ªõp m·∫•y)\n‚Ä¢ V·∫•n ƒë·ªÅ c·ª• th·ªÉ b·∫°n g·∫∑p ph·∫£i\n\nH√£y chia s·∫ª th√™m th√¥ng tin nh√©! üòä`,
        
        `üéØ **C√¢u h·ªèi th√∫ v·ªã!** T√¥i c√≥ th·ªÉ gi√∫p b·∫°n v·ªÅ:\n\nüìö **C√°c m√¥n h·ªçc:**\n‚Ä¢ To√°n, L√Ω, H√≥a, Sinh\n‚Ä¢ VƒÉn, Anh, S·ª≠, ƒê·ªãa\n\nüîß **Ph∆∞∆°ng ph√°p h·ªçc:**\n‚Ä¢ L·∫≠p k·∫ø ho·∫°ch h·ªçc t·∫≠p\n‚Ä¢ K·ªπ thu·∫≠t ghi nh·ªõ\n‚Ä¢ H·ªçc nh√≥m hi·ªáu qu·∫£\n\nB·∫°n mu·ªën t√¨m hi·ªÉu v·ªÅ lƒ©nh v·ª±c n√†o? ü§î`,
        
        `‚ú® **StudySync AI ƒëang s·∫µn s√†ng h·ªó tr·ª£!**\n\nD·ª±a tr√™n c√¢u h·ªèi c·ªßa b·∫°n, t√¥i khuy√™n b·∫°n n√™n:\n‚Ä¢ L√†m r√µ m√¥n h·ªçc c·∫ßn h·ªó tr·ª£\n‚Ä¢ Chia s·∫ª kh√≥ khƒÉn c·ª• th·ªÉ\n‚Ä¢ Cho bi·∫øt m·ª•c ti√™u h·ªçc t·∫≠p\n\nV√≠ d·ª•: "T√¥i h·ªçc l·ªõp 11, g·∫∑p kh√≥ v·ªõi b√†i t·∫≠p ƒë·∫°o h√†m"\n\nH√£y th·ª≠ l·∫°i v·ªõi th√¥ng tin chi ti·∫øt h∆°n! üöÄ`
      ];
      
      selectedResponse = personalizedDefaults[Math.floor(Math.random() * personalizedDefaults.length)];
      console.log('üìã Selected personalized default response');
    }
    
    // Avoid repeating the same response
    if (this.lastResponses.has(selectedResponse)) {
      console.log('üîÑ Response already used recently, selecting alternative...');
      
      // Try to find a different response from the same category
      const alternatives = responses.default.filter(resp => !this.lastResponses.has(resp));
      if (alternatives.length > 0) {
        selectedResponse = alternatives[Math.floor(Math.random() * alternatives.length)];
      } else {
        // Add timestamp to make it unique
        selectedResponse = selectedResponse + `\n\n‚è∞ *${new Date().toLocaleTimeString('vi-VN')}*`;
      }
    }
    
    // Track this response (keep only last 5)
    this.lastResponses.add(selectedResponse);
    if (this.lastResponses.size > 5) {
      const firstResponse = this.lastResponses.values().next().value;
      this.lastResponses.delete(firstResponse);
    }
    
    console.log(`‚úÖ Fallback response selected (${selectedResponse.length} chars)`);
    return selectedResponse;
  }

  /**
   * Main method to get AI response with fallback support
   * @param {string} message - User message
   * @param {Array} conversationHistory - Previous conversation context
   * @returns {Promise<string>} AI response
   */
  async getChatResponse(message, conversationHistory = []) {
    console.log(`ü§ñ Getting AI response using ${this.provider} provider...`);
    console.log(`üìù User message: "${message}"`);
    console.log(`üîß API Key available: ${this.provider === 'openai' ? !!this.apiKey : this.provider === 'gemini' ? !!import.meta.env.VITE_GEMINI_API_KEY : 'N/A'}`);
    
    try {
      let response;
      
      switch (this.provider) {
        case 'openai':
          if (!this.apiKey || this.apiKey === 'your_openai_api_key_here') {
            console.warn('üö® OpenAI API key not properly configured, using fallback');
            return this.getFallbackResponse(message);
          }
          console.log('üîÑ Calling OpenAI API...');
          response = await this.getOpenAIResponse(message, conversationHistory);
          break;
          
        case 'gemini':
          const geminiKey = import.meta.env.VITE_GEMINI_API_KEY;
          if (!geminiKey || geminiKey === 'your_gemini_api_key_here') {
            console.warn('üö® Gemini API key not properly configured, using fallback');
            return this.getFallbackResponse(message);
          }
          console.log('üîÑ Calling Gemini API...');
          try {
            response = await this.getGeminiResponse(message, conversationHistory);
          } catch (geminiError) {
            console.error('‚ùå Gemini API completely failed:', geminiError.message);
            console.log('üîÑ Falling back to intelligent responses...');
            
            // Add a notice about AI service status
            const fallbackWithNotice = `‚ö†Ô∏è **Th√¥ng b√°o:** D·ªãch v·ª• AI ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. T√¥i ƒëang s·ª≠ d·ª•ng ch·∫ø ƒë·ªô tr·∫£ l·ªùi th√¥ng minh.\n\n${this.getFallbackResponse(message)}\n\nüîß **L∆∞u √Ω:** C√°c t√≠nh nƒÉng AI s·∫Ω ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng sau khi ƒë∆∞·ª£c kh·∫Øc ph·ª•c.`;
            
            return fallbackWithNotice;
          }
          break;
          
        case 'local':
          console.log('üîÑ Calling Local API...');
          response = await this.getLocalAIResponse(message, conversationHistory);
          break;
          
        default:
          console.warn(`üö® Unknown provider: ${this.provider}, using fallback`);
          return this.getFallbackResponse(message);
      }
      
      console.log('‚úÖ AI response received successfully:', response ? response.substring(0, 100) + '...' : 'Empty response');
      return response;
      
    } catch (error) {
      console.error('‚ùå AI service error, using fallback response:', {
        provider: this.provider,
        message: error.message,
        status: error.status
      });
      return this.getFallbackResponse(message);
    }
  }

  /**
   * Get study suggestions based on subject
   * @param {string} subject - Subject name
   * @param {string} level - Education level
   * @returns {Promise<Object>} Study suggestions
   */
  async getStudySuggestions(subject, level = 'high-school') {
    const suggestions = {
      'to√°n': {
        topics: ['ƒê·∫°i s·ªë', 'H√¨nh h·ªçc', 'Gi·∫£i t√≠ch', 'X√°c su·∫•t th·ªëng k√™'],
        methods: ['L√†m b√†i t·∫≠p t·ª´ c∆° b·∫£n ƒë·∫øn n√¢ng cao', 'V·∫Ω s∆° ƒë·ªì t∆∞ duy c√¥ng th·ª©c', 'Th·ª±c h√†nh gi·∫£i ƒë·ªÅ thi'],
        resources: ['S√°ch gi√°o khoa', 'B√†i t·∫≠p n√¢ng cao', 'Video b√†i gi·∫£ng online']
      },
      'l√Ω': {
        topics: ['C∆° h·ªçc', 'Nhi·ªát h·ªçc', 'ƒêi·ªán h·ªçc', 'Quang h·ªçc'],
        methods: ['Th√≠ nghi·ªám th·ª±c h√†nh', 'V·∫Ω s∆° ƒë·ªì m·∫°ch ƒëi·ªán', 'Gi·∫£i b√†i t·∫≠p c√≥ h√¨nh v·∫Ω'],
        resources: ['Th√≠ nghi·ªám ·∫£o', 'Video th√≠ nghi·ªám', 'S√°ch b√†i t·∫≠p c√≥ l·ªùi gi·∫£i']
      },
      'h√≥a': {
        topics: ['H√≥a ƒë·∫°i c∆∞∆°ng', 'H√≥a v√¥ c∆°', 'H√≥a h·ªØu c∆°', 'H√≥a ph√¢n t√≠ch'],
        methods: ['H·ªçc thu·ªôc b·∫£ng tu·∫ßn ho√†n', 'Vi·∫øt ph∆∞∆°ng tr√¨nh h√≥a h·ªçc', 'Th·ª±c h√†nh th√≠ nghi·ªám'],
        resources: ['B·∫£ng tu·∫ßn ho√†n t∆∞∆°ng t√°c', 'Video th√≠ nghi·ªám', 'Flashcards c√¥ng th·ª©c']
      }
    };

    return suggestions[subject.toLowerCase()] || {
      topics: ['Ch∆∞a c√≥ d·ªØ li·ªáu cho m√¥n n√†y'],
      methods: ['H·ªçc theo s√°ch gi√°o khoa', 'Tham gia nh√≥m h·ªçc t·∫≠p', 'T√¨m ki·∫øm t√†i li·ªáu b·ªï sung'],
      resources: ['StudySync Community', 'T√†i li·ªáu online', 'Video h·ªçc t·∫≠p']
    };
  }

  /**
   * Generate study plan
   * @param {Object} preferences - User study preferences
   * @returns {Promise<Object>} Generated study plan
   */
  async generateStudyPlan(preferences) {
    const { subjects, timePerDay, level, goals } = preferences;
    
    // This would typically use AI to generate a personalized plan
    // For now, return a template plan
    return {
      plan: {
        daily: `H·ªçc ${timePerDay} ti·∫øng m·ªói ng√†y`,
        weekly: subjects.map(subject => `${subject}: 3 bu·ªïi/tu·∫ßn`),
        monthly: 'Ki·ªÉm tra ti·∫øn ƒë·ªô v√† ƒëi·ªÅu ch·ªânh k·∫ø ho·∫°ch'
      },
      schedule: subjects.map((subject, index) => ({
        subject,
        time: `${7 + index * 2}:00 - ${8 + index * 2}:00`,
        frequency: '3 l·∫ßn/tu·∫ßn'
      })),
      tips: [
        'Ngh·ªâ gi·∫£i lao 10 ph√∫t sau m·ªói 50 ph√∫t h·ªçc',
        '√în t·∫≠p ki·∫øn th·ª©c c≈© tr∆∞·ªõc khi h·ªçc b√†i m·ªõi',
        'Tham gia nh√≥m h·ªçc ƒë·ªÉ th·∫£o lu·∫≠n'
      ]
    }
  }

  /**
   * Test function for debugging AI responses
   * @param {string} testMessage - Message to test
   * @returns {Promise<Object>} Test results
   */
  async testAI(testMessage = "Xin ch√†o AI!") {
    console.log('üß™ Testing AI Service...');
    
    const testResults = {
      provider: this.provider,
      apiKeyConfigured: {
        openai: !!(this.apiKey && this.apiKey !== 'your_openai_api_key_here'),
        gemini: !!(import.meta.env.VITE_GEMINI_API_KEY && import.meta.env.VITE_GEMINI_API_KEY !== 'your_gemini_api_key_here'),
      },
      testMessage,
      startTime: Date.now()
    };

    try {
      const response = await this.getChatResponse(testMessage);
      testResults.success = true;
      testResults.response = response;
      testResults.responseLength = response.length;
      testResults.duration = Date.now() - testResults.startTime;
      
      console.log('‚úÖ AI Test Results:', testResults);
      return testResults;
    } catch (error) {
      testResults.success = false;
      testResults.error = error.message;
      testResults.duration = Date.now() - testResults.startTime;
      
      console.error('‚ùå AI Test Failed:', testResults);
      return testResults;
    }
  }

  /**
   * Clear conversation cache
   */
  clearCache() {
    this.lastResponses.clear();
    this.conversationContext.clear();
    console.log('üßπ AI Service cache cleared');
  }

  /**
   * Check Gemini API status and available models
   * @returns {Promise<Object>} API status information
   */
  async checkGeminiStatus() {
    const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
    
    if (!apiKey || apiKey === 'your_gemini_api_key_here') {
      return {
        status: 'error',
        message: 'API key not configured',
        hasKey: false
      };
    }

    try {
      console.log('üîç Checking Gemini API status...');
      
      // Test API key validity
      const response = await fetch(`https://generativelanguage.googleapis.com/v1/models?key=${apiKey}`);
      
      if (!response.ok) {
        const errorText = await response.text();
        return {
          status: 'error',
          message: `API Error: ${response.status} - ${errorText}`,
          hasKey: true,
          httpStatus: response.status
        };
      }

      const data = await response.json();
      const availableModels = data.models?.map(m => m.name.replace('models/', '')) || [];
      
      return {
        status: 'success',
        message: 'Gemini API is working',
        hasKey: true,
        availableModels,
        totalModels: availableModels.length
      };

    } catch (error) {
      return {
        status: 'error',
        message: `Network error: ${error.message}`,
        hasKey: true,
        error: error.message
      };
    }
  }
}

const aiServiceInstance = new AIService();

// Add debug functions to window for console testing
if (typeof window !== 'undefined') {
  window.debugAI = {
    test: (message) => aiServiceInstance.testAI(message),
    clearCache: () => aiServiceInstance.clearCache(),
    getProvider: () => aiServiceInstance.provider,
    checkKeys: () => ({
      openai: !!(aiServiceInstance.apiKey && aiServiceInstance.apiKey !== 'your_openai_api_key_here'),
      gemini: !!(import.meta.env.VITE_GEMINI_API_KEY && import.meta.env.VITE_GEMINI_API_KEY !== 'your_gemini_api_key_here'),
    }),
    fallbackTest: (message) => aiServiceInstance.getFallbackResponse(message),
    checkGemini: () => aiServiceInstance.checkGeminiStatus(),
    // Quick fix command
    fixGemini: async () => {
      console.log('üîß Running Gemini diagnostics...');
      const status = await aiServiceInstance.checkGeminiStatus();
      console.log('üìä Gemini Status:', status);
      
      if (status.status === 'error') {
        console.log('‚ùå Gemini Issues Detected:');
        console.log('- Message:', status.message);
        console.log('- Has API Key:', status.hasKey);
        
        if (!status.hasKey) {
          console.log('üí° Solution: Add VITE_GEMINI_API_KEY to your .env file');
        } else if (status.httpStatus === 403) {
          console.log('üí° Solution: API key invalid or no access. Get new key from https://makersuite.google.com/app/apikey');
        } else if (status.httpStatus === 404) {
          console.log('üí° Solution: Models not available. Check your Google Cloud project settings');
        }
      } else {
        console.log('‚úÖ Gemini is working! Available models:', status.availableModels);
      }
      
      return status;
    }
  };
  
  console.log('üéØ AI Debug tools available at window.debugAI');
  console.log('üîß Quick commands:');
  console.log('  - window.debugAI.checkGemini() - Check API status');
  console.log('  - window.debugAI.fixGemini() - Run diagnostics');
  console.log('  - window.debugAI.test("hello") - Test AI response');
}

export default aiServiceInstance;